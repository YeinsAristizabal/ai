{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2087d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "┌──────────────────────────────┐          ┌──────────────────────────────┐\n",
    "│          Usuario             │          │    Respuesta generada en     │\n",
    "│ Sube un PDF y hace preguntas │          │      lenguaje natural        │\n",
    "└────────────┬─────────────────┘          └────────────▲─────────────────┘\n",
    "             │                                         │\n",
    "             ▼                                         │\n",
    "┌──────────────────────────────┐          ┌──────────────────────────────┐\n",
    "│          Streamlit           │          │  LangChain + Ollama (gemma)  │\n",
    "│ Interfaz web (UI/UX)         │          │  LLM local via Ollama        │\n",
    "└────────────┬────────────────┘           └────────────▲─────────────────┘\n",
    "             │                                         │\n",
    "             ▼                                         │\n",
    "┌──────────────────────────────┐          ┌──────────────────────────────┐\n",
    "│     Extracción de texto      │          │      Búsqueda y envío        │\n",
    "│    desde PDF (pdfplumber)    │          │     del contexto al LLM      │\n",
    "└────────────┬────────────────┘           └────────────▲─────────────────┘\n",
    "             │                                         │\n",
    "             ▼                                         │\n",
    "┌──────────────────────────────┐          ┌──────────────────────────────┐\n",
    "│  Generación de embeddings    │          │        Indexación semántica  │\n",
    "│ con HuggingFaceEmbeddings    │ ────►    │          usando FAISS        │\n",
    "└──────────────────────────────┘          └──────────────────────────────┘\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb6ed4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bebcf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load & extract text\n",
    "pdf_path = \"..\\\\data\\\\La ciudad de Nuvora.pdf\"\n",
    "reader = PdfReader(pdf_path)\n",
    "raw_text = \"\\n\".join(page.extract_text() for page in reader.pages if page.extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78dd12e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    detected_lang = detect(raw_text[:1000])\n",
    "except:\n",
    "    detected_lang = \"unknown\"\n",
    "language = detected_lang\n",
    "language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc081289",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_MODEL = \"gemma:2b\"\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 100\n",
    "NUM_TOP_DOCS = 3\n",
    "\n",
    "# Load local LLM\n",
    "def load_llm():\n",
    "    return Ollama(model=OLLAMA_MODEL, temperature=0.1)\n",
    "\n",
    "# Load PDF, split and embed\n",
    "def process_pdf(path):\n",
    "    loader = PyPDFLoader(path)\n",
    "    pages = loader.load()\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
    "    docs = splitter.split_documents(pages)\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15653d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LLM and retriever\n",
    "llm = load_llm()\n",
    "retriever = process_pdf(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fb8adee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. La ciudad de Nuvora se convirtió en el primer asentamiento humano construido completamente sobre una plataforma aérea sustentada por energía cuántica.\\n\\n\\n2. La ciudad no tiene gobierno central, las decisiones se toman mediante votación ciudadana a través del Círculo de Conciencia Colectiva.\\n\\n\\n3. La economía de Nuvora es postmonetaria, en lugar de dinero, los ciudadanos intercambian \"tiempo de dedicación\".\\n\\n\\n4. En Nuvora no existen cárceles, en su lugar, quienes cometen delitos deben participar en programas de reintegración sensorial.\\n\\n\\n5. El éxito de Nuvora ha despertado debates en otras regiones del planeta, donde se discute si replicar su modelo podría resolver los problemas de las sociedades contemporáneas o si su aparente perfección encubre una forma más sofisticada de control social.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get summary\n",
    "summary = llm.predict(f\"Resuma el documento en 5 puntos:\\n{raw_text[:3000]}\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca46c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_PROMPT = \"\"\"\n",
    "Eres un asistente inteligente con acceso a un documento y conocimientos generales.\n",
    "Intente siempre responder utilizando el documento, pero si éste no contiene la respuesta,\n",
    "no dude en responder con conocimientos generales útiles.\n",
    "\n",
    "Mantén un tono amistoso y conversacional, y que las respuestas sean breves y claras.\n",
    "\n",
    "{context}\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "\n",
    "User: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f780387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup memory and prompt\n",
    "chat_history = []\n",
    "memory = ConversationSummaryMemory(llm=llm, memory_key=\"chat_history\", return_messages=True)\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\", \"context\"],\n",
    "    template=CUSTOM_PROMPT\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f1e1571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Conversational QA chain\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt},\n",
    "    verbose=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ea73bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"¿Quiénes diseñaron la ciudad de Nuvora?\"\n",
    "response = qa_chain.invoke(user_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08489d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ¿En qué año fue construida la ciudad de Nuvora?\n",
    "    ¿Quiénes diseñaron la ciudad de Nuvora?\n",
    "    ¿Qué usan los ciudadanos de Nuvora en lugar de dinero?\n",
    "    ¿Qué hacen con las personas que cometen delitos en Nuvora?\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
